spring.application.name=spark-demo
# C?u hï¿½nh c? b?n Spring Boot
server.port=8085

# C?u hï¿½nh PostgreSQL
spring.datasource.url=jdbc:postgresql://localhost:5432/spark_demo_db?currentSchema=public&useSSL=false&connectTimeout=30000&socketTimeout=30000
spring.datasource.username=admin
spring.datasource.password=password
spring.datasource.driver-class-name=org.postgresql.Driver

# C?u hï¿½nh HikariCP
spring.datasource.hikari.connection-timeout=30000
spring.datasource.hikari.idle-timeout=300000
spring.datasource.hikari.max-lifetime=1800000
spring.datasource.hikari.minimum-idle=5
spring.datasource.hikari.maximum-pool-size=10

spring.jpa.hibernate.ddl-auto=update
spring.jpa.show-sql=false
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect
spring.jpa.properties.hibernate.connection.autocommit=true
spring.jpa.properties.hibernate.connection.isolation=2

# C?u hï¿½nh Kafka
# ??a ch? Kafka broker - khi Spring Boot ch?y LOCAL, Kafka ?ang trong Docker => dï¿½ng localhost
# ================================
# Kafka Broker Configuration
# ================================
spring.kafka.bootstrap-servers=localhost:9092,localhost:9093

# ================================
# Kafka Producer Configuration
# ================================
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.acks=all
spring.kafka.producer.retries=10
spring.kafka.producer.properties.retry.backoff.ms=500
spring.kafka.producer.properties.request.timeout.ms=20000


# ================================
# Kafka Consumer Configuration
# ================================
spring.kafka.consumer.group-id=spark-demo-group
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.max-poll-records=500

# ================================
# Listener & Topic Config
# ================================
spring.kafka.listener.missing-topics-fatal=false

# ================================
# Kafka Topic Auto-Create (Note: This is for Broker, not Spring)
# ================================
# N?u b?n mu?n Kafka t? t?o topic, ??m b?o ?ã b?t trong Docker:
# KAFKA_AUTO_CREATE_TOPICS_ENABLE=true



# C?u hï¿½nh Spark (n?u c?n)
spark.master=spark://localhost:7077
spark.driver.host=localhost
spring.jvm.args=--add-exports=java.base/sun.nio.ch=ALL-UNNAMED

# Actuator endpoints cho Prometheus
management.endpoints.web.exposure.include=health,info,prometheus
management.metrics.enable.application=true
management.metrics.enable.jvm=true
management.metrics.enable.process=true
